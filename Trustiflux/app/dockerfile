FROM python:3.13-slim
WORKDIR /app

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    git \
    wget \
    curl \
    cmake \
    build-essential \
    libcurl4-openssl-dev \
    python3-dev \
    && rm -rf /var/lib/apt/lists/*

RUN git clone --branch gguf-v0.16.2 https://github.com/ggerganov/llama.cpp
RUN cd llama.cpp && cmake -B build && cmake --build build --config Release -j 8

RUN git clone --branch v2.8.1 https://github.com/oobabooga/text-generation-webui
WORKDIR /app/text-generation-webui
RUN GPU_CHOICE=N USE_CUDA118=FALSE LAUNCH_AFTER_INSTALL=FALSE INSTALL_EXTENSIONS=TRUE ./start_linux.sh

EXPOSE ${CONTAINER_PORT:-7860} ${CONTAINER_API_PORT:-5000} ${CONTAINER_API_STREAM_PORT:-5005}
WORKDIR /app/text-generation-webui
CMD umask 0002 && export HOME=/app/text-generation-webui && ./start_linux.sh --listen